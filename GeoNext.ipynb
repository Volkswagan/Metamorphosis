{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a3e97b2-7790-4ea6-8dcb-009e942019c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add prefix 'emp_' to all column names\n",
    "new_column_names = [f\"emp_{col}\" for col in df.columns]\n",
    "\n",
    "for old_col, new_col in zip(df.columns, new_column_names):\n",
    "    df = df.withColumnRenamed(old_col, new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0903c42-778c-4fc7-802d-da17bf11a576",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Input data\n",
    "data = [([1, 2, 3],), ([4, 5],), ([[6, 7]],)]\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df = spark.createDataFrame(data, [\"nested_list\"])\n",
    "\n",
    "# Flatten the DataFrame by exploding each nested list to create a new row for each element\n",
    "while df.select(\"nested_list\").dtypes[0][1] == 'array<array<int>>':\n",
    "    df = df.withColumn(\"nested_list\", explode(\"nested_list\"))\n",
    "\n",
    "df = df.withColumn(\"flattened_list\", explode(\"nested_list\")).select(\"flattened_list\")\n",
    "\n",
    "# Collect the result as a flat list\n",
    "result = df.select(\"flattened_list\").rdd.flatMap(lambda x: x).collect()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a92f4e6f-6955-491e-aabc-f6282d284148",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "secret_value = dbutils.secrets.get(scope=\"my_scope\", key=\"my_secret_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0eea16c-0386-44e5-aeaf-a8b427b6310e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# NB 1\n",
    "input_value = dbutils.widgets.get(\"input_value\")\n",
    "output_value = int(input_value) + 2\n",
    "def add_numbers(a, b):\n",
    "    return a + b\n",
    "#dbutils.notebook.exit(\"\")\n",
    "dbutils.notebook.exit(str(output_value))\n",
    "#NB 2\n",
    "notebook_result = dbutils.notebook.run(\"/Shared/other_notebook\", 60, {\"input_value\": input_value})\n",
    "print(notebook_result)\n",
    "result = add_numbers(3, 5)\n",
    "print(f\"Result of addition: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78f6f822-732d-44b7-8dab-da7766331126",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def is_even(number):\n",
    "    return number % 2 == 0\n",
    "is_even_udf = udf(is_even, BooleanType())\n",
    "df1 = df.withColumn(\"is_even\", is_even_udf(df[\"number\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d8570be-2701-448a-a5e7-89889c59be34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "PERMISSIVE(default), DROPMALFORMED, FAILFAST\n",
    "ERRORIFEXIST(default), ingore, append, overwrite\n",
    "\n",
    "from, join, on, where, group by, having, select, distinct, order by, limit\n",
    "\n",
    "Node size: 16 CPU cores, 64 GB RAM.\n",
    "Executors per node: 3 executors.\n",
    "Executor size: 5 CPU cores, 21 GB RAM.\n",
    "\n",
    "Total capacity depends on the number of nodes N: 16√óùëÅ CPU cores, 64√óùëÅGB RAM.\n",
    "Total parallel tasks: 15√óùëÅ | 15√óN tasks (depending on N).\n",
    "Parallel tasks with 4 executors: 20 tasks.\n",
    "Number of tasks for 10.1 GB CSV: 81 tasks."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "GeoNext",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
